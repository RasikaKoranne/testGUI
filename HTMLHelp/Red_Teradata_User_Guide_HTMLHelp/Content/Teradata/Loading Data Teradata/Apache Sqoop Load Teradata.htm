<!DOCTYPE html>
<html xmlns:MadCap="http://www.madcapsoftware.com/Schemas/MadCap.xsd" lang="en-us" xml:lang="en-us" data-mc-search-type="Stem" data-mc-help-system-file-name="Default.xml" data-mc-path-to-help-system="../../../" data-mc-toc-path="Loading Data" data-mc-target-type="WebHelp2" data-mc-runtime-file-type="Topic" data-mc-preload-images="false" data-mc-in-preview-mode="false">
    <head>
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <meta charset="utf-8" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
        <meta name="msapplication-config" content="../../../Skins/Favicons/browserconfig.xml" />
        <link rel="icon" sizes="16x16" href="../../../Skins/Favicons/favicon-16x16.png" /><title>Apache Sqoop Load</title>
        <link href="../../../Skins/Default/Stylesheets/Slideshow.css" rel="stylesheet" type="text/css" data-mc-generated="True" />
        <link href="../../../Skins/Default/Stylesheets/TextEffects.css" rel="stylesheet" type="text/css" data-mc-generated="True" />
        <link href="../../../Skins/Default/Stylesheets/Topic.css" rel="stylesheet" type="text/css" data-mc-generated="True" />
        <link href="../../../Skins/Default/Stylesheets/Components/Styles.css" rel="stylesheet" type="text/css" data-mc-generated="True" />
        <link href="../../../Skins/Default/Stylesheets/Components/Tablet.css" rel="stylesheet" type="text/css" data-mc-generated="True" />
        <link href="../../../Skins/Default/Stylesheets/Components/Mobile.css" rel="stylesheet" type="text/css" data-mc-generated="True" />
        <link href="../../Resources/Stylesheets/wmd-onlinehelp-style.css" rel="stylesheet" type="text/css" />
        <link href="../../Resources/tablestyles/note.css" rel="stylesheet" data-mc-stylesheet-type="table" />
        <link rel="icon" sizes="16x16" href="../../../Skins/Favicons/favicon-16x16.png" />
        <script src="../../../Resources/Scripts/jquery.min.js" type="text/javascript">
        </script>
        <script src="../../../Resources/Scripts/require.min.js" type="text/javascript" defer="defer">
        </script>
        <script src="../../../Resources/Scripts/require.config.js" type="text/javascript" defer="defer">
        </script>
        <script src="../../../Resources/Scripts/foundation.min.js" type="text/javascript" defer="defer">
        </script>
        <script src="../../../Resources/Scripts/plugins.min.js" type="text/javascript" defer="defer">
        </script>
        <script src="../../../Resources/Scripts/MadCapAll.js" type="text/javascript" defer="defer">
        </script>
    </head>
    <body>
        <div class="nocontent">
            <div class="MCBreadcrumbsBox_0 breadcrumbs" role="navigation" aria-label="Breadcrumbs" data-mc-breadcrumbs-divider=" &gt; " data-mc-breadcrumbs-count="3" data-mc-toc="True"><span class="MCBreadcrumbsPrefix">You are here: </span>
            </div>
        </div>
        <div role="main" id="mc-main-content">
            <h2>Apache Sqoop Load</h2>
            <p>The <b>Apache Sqoop load</b> type enables loading data directly from Hive/HDFS to any (non-Hive) targets, however, for loading data directly from Hive into Teradata, it is recommended to use the TPT functionality instead.</p>
            <p>When processing Teradata loads from Hive/HDFS using Apache Sqoop, WhereScape recommends that you use vendor supplied drivers, such as ‘Hortonworks Connector for Teradata’.</p>
            <p>Scheduler loads and Apache Sqoop loads from a Hive connection to a Hive target are not supported.</p>
            <p>The following known issues exist when using Sqoop loads with the generic JDBC driver on Teradata:</p>
            <p>When processing Teradata loads from Hive/HDFS using Apache Sqoop, WhereScape recommends that you use vendor supplied drivers, such as ‘Hortonworks Connector for Teradata’.</p>
            <p>Scheduler loads and Apache Sqoop loads from a Hive connection to a Hive target are not supported.</p>
            <p>The following known issues exist when using Sqoop loads with the generic JDBC driver on Teradata:</p>
            <ol>
                <li value="1">Sqoop loads from Hive to Teradata fail if column names and titles are different.</li>
                <li value="2">For Sqoop loads from Hive to Teradata where column names and titles are the same, complete the following to enable the load to work.</li>
            </ol>
            <h4>To load tables directly from HDFS/Hive into Teradata target databases using the Apache Sqoop load:</h4>
            <ol>
                <li value="1">Ensure the relevant <b>Data Warehouse connection</b> has the following fields set:<ul><li>JDBC Connection string (JDBC URL)</li><li>JDBC Driver Class Name</li><li>Omit Sqoop Driver Option - tick this check-box for loads into Oracle target databases</li><li>JDBC User ID </li><li>JDBC Password</li></ul><p><img src="../../Images/Teradata_images/Loading Data/Apache Sqp Load_1.png" /></p><table style="width: 100%;margin-left: 0;margin-right: auto;mc-table-style: url('../../Resources/tablestyles/note.css');" class="TableStyle-note" cellspacing="0"><col class="TableStyle-note-Column-Column1" /><thead><tr class="TableStyle-note-Head-Header1"><th class="TableStyle-note-HeadD-Column1-Header1">Note</th></tr></thead><tbody><tr class="TableStyle-note-Body-Body1"><td class="TableStyle-note-BodyA-Column1-Body1" role="rowheader">Users loading into Teradata from a Hive or Hadoop connection using the Teradata connection manager for Sqoop who need to load into more than one database will need to add DATABASE=$OBJECT_DATABASE$ into their JDBC Connection String (JDBC URL) field on their Teradata DataWarehouse connection, e.g. jdbc:teradata://192.168.60.226/DATABASE=$OBJECT_DATABASE$.
BDA will replace $OBJECT_DATABASE$ with the database containing their load table when doing an Apache Sqoop load</td></tr></tbody></table></li>
                <li value="2">When doing loads from Hadoop connections, ensure the Hadoop connection has its <b>BDA server host</b> and <b>port</b> fields set in addition to Hive connections.<p><img src="../../Images/Teradata_images/Loading Data/Hadoop Loadhdfs.png" /></p></li>
                <li value="3">Browse the desired <b>Hadoop/Hive connection</b>.</li>
                <li value="4"><b>Drag and Drop </b>the table from the Hadoop/Hive connection on the right hand-side into the middle pane.<ul><li>Change the table name if necessary and select the relevant target location to place the table from the drop-down list.</li></ul><p><img src="../../Images/UserGuide_Images/Loading Data/Apache Sqoop Load_2.png" /></p><table style="width: 100%;margin-left: 0;margin-right: auto;mc-table-style: url('../../Resources/tablestyles/note.css');" class="TableStyle-note" cellspacing="0"><col class="TableStyle-note-Column-Column1" /><thead><tr class="TableStyle-note-Head-Header1"><th class="TableStyle-note-HeadD-Column1-Header1">Note</th></tr></thead><tbody><tr class="TableStyle-note-Body-Body1"><td class="TableStyle-note-BodyA-Column1-Body1" role="rowheader">The option <b>Add meta data columns to table</b> is used for creating load tables that are used in creating Data Vault objects.&#160; If this option is selected, two DSS columns (<b>dss_record_source</b> and<b> dss_load_date</b>) are included in the meta data for the table and are populated by transformations. These two DSS columns could equally be applied to other load tables not used in a Data Vault system but are particularly important to comply with the Data Vault standards. Refer to <a href="../../User Guide/Data Vaults/Data Vaults.htm">Data Vaults</a> for details.</td></tr></tbody></table></li>
                <li value="5">Select <b>Apache Hadoop Load</b> from the <b>Load Type</b> drop-down list.<p><img src="../../Images/UserGuide_Images/Loading Data/Apache Sqoop Load_3.png" /></p></li>
                <li value="6">Click the<b> Source </b>tab to add any Apache Sqoop specific options:<ul><li>Temporary HDFS Directory - Loading from a Hive source to the data warehouse is implemented in two steps. First, the data is extracted from the Hive table into a temporary HDFS directory. Then, this temporary directory is loaded using "sqoop export". The location of the temporary directory can be configured in RED on the source tab of the load table. When this field is left blank, the default is "/tmp".</li><li>Generic Hadoop Arguments - This field allows adding additional arguments just after the Sqoop command keyword, in this case it is import, in the Sqoop command line.</li><li>Additional Tool Arguments - This field allows adding additional arguments after the generated Sqoop command line. </li></ul><p><img src="../../Images/UserGuide_Images/Loading Data/Apache Sqoop Load_4.png" /></p><table style="width: 100%;margin-left: 0;margin-right: auto;mc-table-style: url('../../Resources/tablestyles/note.css');" class="TableStyle-note" cellspacing="0"><col class="TableStyle-note-Column-Column1" /><thead><tr class="TableStyle-note-Head-Header1"><th class="TableStyle-note-HeadD-Column1-Header1">Note</th></tr></thead><tbody><tr class="TableStyle-note-Body-Body1"><td class="TableStyle-note-BodyA-Column1-Body1" role="rowheader">Sqoop loads from Hive to Teradata fails if column names and titles are different. 
Please ensure column names and titles are the same and then, on the Load table properties, go to the Source tab and on the Generic Hadoop Arguments field specify the following command: -Dsqoop.export.records.per.statement=1.&#160;&#160;&#160;<img src="../../Images/Teradata_images/Loading Data/Apache Sqp Load_6_641x434.png" style="width: 641;height: 434;" /><br /></td></tr></tbody></table></li>
                <li value="7">Click <b>Create and Load </b>to create and load the table.</li>
            </ol>
        </div>
    </body>
</html>